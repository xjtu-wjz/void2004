---
title: 深度学习基础概念
date: 2024-11-01
updated: 2024-11-01
categories: Research
image: https://raw.githubusercontent.com/xjtu-wjz/void2004/refs/heads/main/pics_for_post/deep-learning_basic.webp
tags:
  - 科研
top: 1
---

近几年深度学习领域的基础概念和模型基础。

# 残差连接
在传统神经网络中，信息会从一个层传递到下一个层，在传递的过程中会损失部分信息。在残差连接技术中，在原本layer的输出基础上又加了一个跨层的输出，将该层的输入加在了输出上，从而保留更多的信息。这个跨层链接可以看做是一个从输入到输出的捷径。

残差连接的公式为：
$$y=f(x)+x$$

前向传播时，输出和输入加在一起，作为该层新的输出传递到下一层进行处理；反向传播中，残差连接使得梯度可以更容易地传递到之前的层，加速模型收敛。

到这里就是残差连接的全部思想。我们不妨再多看一点：为何需要这一步捷径(skip connect)呢？

我们知道，神经网络通过误差损失的链式反向传播来更新参数，在一定程度上，模型的性能当然是层数越多，性能越好。但是对于计算过程中的多次求导来看：
![alt text](../../materials/8fbd303ea5c929ef86273491a7099059.png)

其中$cost$对x求导为：

![alt text](../../materials/8adaaf0a702c5b3a00c7c3071016c58c.png)

一旦其中一个导数非常小，就很有可能出现一系列导数求导最后发生梯度消散。但如果使用残差链接，那么梯度的最小值也能保证有一个常数项1，这时候即便有一层的导数非常小，损失也可以顺利反向传播。

残差连接的作用不仅于此，还可以挽救训练过程中权重矩阵的退化。详细可见resnet原论文。


# self-attention mechanism
注意区分 注意力机制和自注意力机制之间的区别，二者有差距。

注意力机制本质是令模型为数据的不同部分分配不同的关注程度，这种策略类似于人类大脑的注意力机制。attention mechanism 在处理序列数据和做图像处理的时候能够很好的关注不同位置数据的局部特征，并将哪怕位置很远的元素相互关联。

首先我们定义给入的询问为$query$。对于询问q，我们定义给定的输入x为：$x=[x_{1},x_{2},x_{3},......]$。

接着我们引入键向量（key）和值向量（value）。键向量的每一维值与q向量中的每一维相互对应，键向量存在的意义是帮助我们后续衡量输入中的不同元素与询问的相关性，从而决定输出。值向量表征的是实际的信息，这些信息将会在后续被加权求和得到最终的输出。

举一个例子：现在我们需要翻译（query）一个句子：i love cat, 将它翻译成法语：J'aime les chats。输入"i love cat"可以转换为词向量：
$$i → x_1$$
$$love → x_2$$
$$cat → x_3$$
引入转换矩阵$W$,计算得出源输入$x$对应的键向量：
$$K_1=W_K x_{1}$$
$$K_2=W_K x_{2}$$
$$K_3=W_K x_{3}$$
$$K=[K_1,K_2,K_3]$$

此外，我们再计算输入的值向量，将输入向量表征出来：
$$V_1=W_V x_{1}$$
$$V_2=W_V x_{2}$$
$$V_3=W_V x_{3}$$
$$V=[V_1,V_2,V_3]$$

为了得到最终的输出，我们对值向量进行加权求和得到output.如何计算呢？首先利用键向量得到他们的兼容性和加权权重。

$$score(q,K_1)=q*K_1$$
$$score(q,K_2)=q*K_2$$
$$score(q,K_3)=q*K_3$$
使用softmax将兼容性分数转化为权重：
$$[weight_1 = \frac{\exp(\text{score}(q, k_1))}{\sum_{i=1}^3 \exp(\text{score}(q, k_i))}]$$
$$[weight_2 = \frac{\exp(\text{score}(q, k_2))}{\sum_{i=1}^3 \exp(\text{score}(q, k_i))}]$$
$$[weight_3 = \frac{\exp(\text{score}(q, k_3))}{\sum_{i=1}^3 \exp(\text{score}(q, k_i))}]$$

这就是每一维元素获得的权重，最后将他们与值向量相乘求和即可得到输出向量：
$$[\text{output} = \text{weight}_1 \cdot \mathbf{v}_1 + \text{weight}_2 \cdot \mathbf{v}_2 + \text{weight}_3 \cdot \mathbf{v}_3]$$

# 马尔科夫/非马尔科夫过程
马尔科夫过程是一种随机过程，在马尔科夫过程中，变量的下一个状态仅与当前状态有关而与历史状态无关。非马尔科夫过程就是马尔科夫过程的反面，非马尔科夫过程的状态还可能会与历史状态有关，因此预测非马尔科夫过程还需要对历史路径进行建模。

马尔科夫链即指沿时间轴发生的马尔科夫过程。在过程中系统在每一个离散时间点上对应的状态仅与上一个离散时间点的状态相关。

# 表示学习
如果有对原始数据经过提炼的更好表达，往往会使模型的训练事半功倍。表示学习做的就是这样一件事--通过量化数据不同维度的特征，然后使用这些特征表示数据，并让模型进行学习，发现使用特征表示的数据中的联系与潜在特征。简单来说，表示学习的任务是首先确定模型的输入$x$，并让模型依据这个$x$学习。

现有的许多方法都在表示学习的范畴，知名的比如卷积和语音序列处理就是将图像和语音数据转换成向量的形式，再送给网络发掘特征。

但是表示学习也面临着表示崩溃（Representation Collapse）的危机。表示崩溃是指模型在训练过程中学到的表示（嵌入向量或者特征向量等）逐渐趋于相同，模型失去了区分不同任务和数据的能力。常见的原因有模型在学习过程中过度拟合了部分任务或者数据，从而导致模型的表示过于泛化，忽略了不同任务数据之间的差异。还有一种原因是模型参数共享。在处理不同任务时模型可能会共享部分基础参数，但是如果共享参数过多，模型就可能学习到一些对于所有任务都适用的表示而无法针对benchmark特化。
