---
title: Paper reading--《Denoising Diffusion Probabilistic Models》
date: 2024-11-03
updated: 2024-11-03
categories: Paper-reading
image: https://raw.githubusercontent.com/xjtu-wjz/void2004/refs/heads/main/pics_for_post/ASurvey%20on%20Multimodal%20Large%20Language%20Models.webp
tags:
  - 科研
  - LLM
top: 1
---

扩散模型的开山之作[Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239)。这篇帖子并不把重心放在详细的公式推导上，在看见树木之前我们最好先看得见森林。

# 什么是diffusion model?
现在假如我们想要生成一张256x256x3的图片，那么我们需要知道其中每一个像素点需要安放在哪一个位置上。换句话说，我们需要得知像素$x$和其对应位置$p$之间的函数关系$f(x)$。但事实上这个分布函数是非常复杂，或者几乎是不可能获取的。

这时候我们就需要换一种思路，**找到能够满足我们的数据分布的基本似然函数**。这就是diffusion model的最初构想。diffusion model（扩散模型）来源于物理学中热力学扩散的概念，核心有正向扩散和反向扩散两部分，分别对应加噪和去噪的过程。扩散模型的核心思想来源于模拟物质在空间中的扩散过程，只不过在具体任务中“物质”对应的是样本点，“空间”指的是数据空间。

# 正向扩散
为什么要加噪（正向扩散）呢？因为原有的图像数据具有非常复杂的特征，数据分布难以把握，加噪可以简化训练流程，对图像加噪最后形成纯高斯噪声的过程也是一种数据加强的过程，模型更容易学习到鲁棒的图像特征。同时加噪过程也可以看做是一个马尔科夫链，每一步加上去的噪声都是基于当前状态的。在一步步加噪过程中模型的学习量更丰富，训练过程更稳健。

# 反向扩散
反向扩散是正向扩散的逆过程，也可以看做逆马尔科夫链，逐步从当前的数据中去处噪声直到恢复原来的数据分布。每一次去噪都基于当前的状态，在去噪过程中模型就可以有效学习数据的核心特征，并学习如何一步步从完全随机的状态出发，复原得到原始图片或者生成其他的图片。

