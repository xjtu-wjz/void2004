---
title: Paper reading--生成模型训练加速
date: 2024-11-28
updated: 2023-11-28
categories: Paper-reading
image: https://raw.githubusercontent.com/xjtu-wjz/void2004/refs/heads/main/pics_for_post/_2024-11-24%20211237.webp
tags:
  - 科研
  - Generative Models
top: 1
---


# REPRESENTATION ALIGNMENT FOR GENERATION: TRAINING DIFFUSION TRANSFORMERS IS EASIER THAN YOU THINK

考虑：可以使用外部的视觉编码器加强生成模型的表示学习。只是在这期间需要考虑这几个问题：

- 输入对齐。一般的视觉编码器处理的是干净的图片输入$x$，而扩散模型处理的是带噪声的，经过VAE压缩的输入向量$z(x)$；

- 任务对齐。visual encoder一般是为了识别和分类而建立，但是扩散模型主要用于生成。

在实验中观察到自监督视觉编码器的语义表示明显超过扩散模型，并且扩散模型自身已经表现出了和自监督视觉编码器的弱对齐，并且对齐程度是可以随着模型大小提升和数据量提升而提高的。基于这些发现，提出可以使用视觉编码器的信息作为额外的监督，引导模型生成高质量图像。

核心想法比较简单，在损失中加入对齐项。

对于一个视觉编码器$f$,它的输入是干净图像$x^*$，输出是$y^*$。我们设$h_t=f_{\theta}(z_t)$表示扩散模型在时间步t时的隐藏状态。$h_{\phi}(h_t)$是一个可训练多映射头，将扩散模型的中间隐藏状态映射到和$y^*$相同的空间中。接着定义对齐损失：

$$
\mathcal{L}_{\text{REPA}}(\theta, \phi) := -\mathbb{E}_{\mathbf{x}_*, \epsilon, t} \left[ \frac{1}{N} \sum_{n=1}^{N} \text{sim}(\mathbf{y}_*^{[n]}, h_\phi(\mathbf{h}_t^{([n])})) \right],
$$

其中$sim$是预先自定义的相似度函数。

在扩散模型训练的损失中，依靠权重$\lambda$组合成完整的损失函数：

$$
\mathcal{L} := \mathcal{L}_{\text{velocity}} + \lambda \mathcal{L}_{\text{REPA}}
$$

