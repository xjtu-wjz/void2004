---
title: Paper reading--《Efficiency for Free--Ideal Data Are Transportable Representations》
date: 2024-11-06
updated: 2023-11-06
categories: Paper-reading
image: https://raw.githubusercontent.com/xjtu-wjz/void2004/refs/heads/main/pics_for_post/100468452_p0.webp
tags:
  - 科研
  - LLM
top: 1
---

文章提出，使用一个公开的，并不针对数据集或者特定的下流任务进行特化的模型已经可以产生高质量的训练数据，并且这些数据可以有效帮助加速模型训练过程和提升训练性能。基于这个发现，提出了Representation Learning Accelerator（RELA）框架，使用公开的模型生产高质量训练数据，并增加自监督学习策略提升训练效果和训练速度。

# Intro
随着近年来深度学习领域数据量的爆发式增长，随之而来的还有若干重要训练问题：
- 当前的深度学习模型普遍需要人工构造高质量标注数据集，而人工标注过程会消耗大量社会资源。
- 使用越来越大的数据训练模型，所需要消耗的计算资源也越来越多。

为了解决以上问题，研究者先后引入了自监督学习（SSL）和数据集蒸馏方法。前者无需人工标注数据，后者大大压缩了原始数据集。但这些方法也存在着自己的局限性，导致原来的问题并没有完全解决的同时反而引入了新的挑战：
- 自监督学习产生的标签是次优化的，训练效率不如利用人工标签那样高效；
- 数据集蒸馏的开销非常大，可能将数据集蒸馏的过程消耗和不进行蒸馏直接训练多出的消耗相当。

对此文章提出了一个崭新的视角--网络上存在大量的预训练好的模型，它们可以被视作已经存放了部分知识。利用这些先验模型也许可以帮助我们提升自己的模型训练效率。但值得注意的是，网上的预训练模型并不针对特定的下游任务和数据集。因此又提出open problem:我们该如何才能利用这些不限定数据集和任务的先验模型来加速针对某一特定下游任务的模型的训练效率？于是RELA应运而生。

贡献分为五方面：
- 揭示了数据的哪些特性可以提升/降低训练效率。
- 从data-centric视角揭示了哪些因素会造成了自监督学习的低效率问题。
- 提供了一套量化在优化数据集上训练的模型的泛化能力的方法。
- 提出RELA方法，能够产生加速模型训练的高质量数据集，并且确保模型在产生数据集上的泛化性能。
- 将RELA方法应用于众多任务场景，网络架构和数据类型，在相同甚至更少的预算的前提下取得了相同甚至更优的性能。

# 能够提升训练效率的数据属性
#### 从数据驱动的视角统一监督学习和自监督学习
传统自监督学习和监督学习其实都能看成是对从样本空间$D_X$到目标空间$D_Y$的映射关系的学习。两种学习范式种都需要生成目标：
$$( D_Y = \{y \mid y = \psi(x) \text{ s.t. } x \sim D_X\} )$$

只不过在监督学习中，目标空间是由人工手动标注的，在训练过程中不变；而自监督学习范式中的标签，例如在BYOL方法中，它使用学习模型 $(\phi_\theta)$ 的指数移动平均（Exponential Moving Average, EMA）版本来动态生成目标 $(y = \text{EMA}[\phi_\theta](x))$。这些目标随着模型 $(\phi_\theta)$ 的不断更新而动态变化。

既然都是从输入空间到生成空间的映射，那么接着就从输入和目标两方面探索数据特性对训练效率的影响。

#### 对数据驱动学习的理论和实践分析
为了建立简单但又足够复杂，能够较好模拟现实分布但又可控的数据集，文章构建了一个满足双峰高斯分布的数据集：
>给定两个高斯分布$N_0(\mu_1, \Sigma^2 I)$和$N_1(\mu_2, \Sigma^2 I)$，其中$\mu_1$和$\mu_2$是两个分布的均值，$\Sigma^2$是分布方差，接着构建双峰高斯分布：
$$[ G := {(x, y) \mid x = (1 - y) \cdot x_0 + y \cdot x_1 } ] 其中 ( y \sim \text{Bernoulli}(p = 0.5) ), ( x_0 \sim N_0 ), ( x_1 \sim N_1 ).$$

接着定义用于学习表示的模型：
$$[ f_\theta(x) := \sigma \left( \theta[1] \cdot \text{ReLU}(\theta[2]x + \theta[3]) + \theta[4] \right) ]$$

可以认为是对输入的数据表示做第一次线性变换后送入relu函数激活，再做一次线性变换送入sigmoid函数。



# 方法
总体分为两部分，RELA-D用于生成高质量数据；RELA-F用于指引模型如何利用数据进行训练。

#### RELA-D
两部分，第一部分，使用预训练模型学习能够在不同模型之间，甚至模型预测和人类标注之间迁移的表示，并和原数据$D_{X}$组合。对于$D_{X}$，使用最基本的数据增强。

#### RELA-f
具体地构造了这样的损失函数:
$$[ \lambda \cdot L_{\text{RELA}} + (1-\lambda) \cdot L_{\text{SSL}}, ] 其中 [ L_{\text{RELA}} := \mathbb{E}_{x, y \sim (D_X, R_Y)}[\ell(W\phi_\theta(x) - b, y)].]$$

$\lambda$是引入的算子，在训练初期阶段令其为1，因为训练初期自监督学习未进入平稳阶段，这个时候使用$RELA$提供监督。待后续ssl进入平稳阶段后，动态调整$\lambda$以令自监督学习占据更多权重。
