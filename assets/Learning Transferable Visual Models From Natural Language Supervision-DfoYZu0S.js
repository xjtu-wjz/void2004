import{_ as c}from"./ValaxyMain.vue_vue_type_script_setup_true_lang-D6WepyqT.js";import{b as h,e as u,w as s,f as d,a as g,p as m,r as n,g as a,h as e}from"./app-B5BMfZs9.js";const x="/assets/LD1-B5qPOF8x.png",f=a("p",null,"一句话概括，clip介绍了一种将自然语言监督引入计算机视觉领域的方法（或者说，一类新的encoder）。为后面包括LDM等工作使用自然语言作为约束引入图像生成提供了启发。",-1),w=a("h1",{id:"abstract-intro",tabindex:"-1"},[e("Abstract & Intro "),a("a",{class:"header-anchor",href:"#abstract-intro","aria-label":'Permalink to "Abstract & Intro"'},"​")],-1),b=a("p",null,"NLP领域，使用web-scale级别的数据进行训练取得了巨大成功，但是在计算机视觉领域，使用人工标记的高质量数据集训练依然是主流做法。文章的动机就是能否像NLP领域一样，将文本学习引入到图像学习中，使得模型可以学习到对图像更加丰富的表征学习？",-1),v=a("p",null,"引入文本增强对图像的学习好处有这几个：",-1),_=a("ul",null,[a("li",null,"数据集庞大，可以轻松获得；"),a("li",null,"自然语言描述能力很强，使用自然语言加强图像学习可以使模型不仅学习的是一个表征，而是将表征和语言联系起来，实现灵活的zero-shoting。")],-1),y=a("h1",{id:"datasets",tabindex:"-1"},[e("Datasets "),a("a",{class:"header-anchor",href:"#datasets","aria-label":'Permalink to "Datasets"'},"​")],-1),M=a("p",null,"该方法贡献还有一个，就是提供了高质量的text-image对数据集。尽管先前已经有一个庞大的图文数据集YFCC100M，但是数据集质量堪忧，其中也有大量甚至不带文本的图像数据。对他们进行选择，最终只得到了1500万张图片，这显然都不是很好的选择。因此作者从网络中构建了全新的文本-图像对数据集WIT，包含四亿对数据。",-1),k=a("h1",{id:"pre-training-method",tabindex:"-1"},[e("Pre-training method "),a("a",{class:"header-anchor",href:"#pre-training-method","aria-label":'Permalink to "Pre-training method"'},"​")],-1),L=a("p",null,"最开始，文章的想法是选择Vir-Tex之类类似的方法，使用从零开始训练一个识别图像的模型（CNN,RESNET）和一个进行文本处理的模型（transformer），但是后来发现训练效率（选择预训练方法时将这一项作为重要指标）十分不好。因此作者调转方向，不去训练预测模型，而是一个对比模型，预测一个图像和一个文本是不是属于一个pair。",-1),z=a("p",null,[e("具体实现如下。由于输入的是文本-图像对（假设有n个图像，n个描述文本），因此随意组合共有"),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("msup",null,[a("mi",null,"n"),a("mn",null,"2")])]),a("annotation",{encoding:"application/x-tex"},"n^2")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.8141em"}}),a("span",{class:"mord"},[a("span",{class:"mord mathnormal"},"n"),a("span",{class:"msupsub"},[a("span",{class:"vlist-t"},[a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.8141em"}},[a("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[a("span",{class:"pstrut",style:{height:"2.7em"}}),a("span",{class:"sizing reset-size6 size3 mtight"},[a("span",{class:"mord mtight"},"2")])])])])])])])])])]),e("中组合，除了其中原本正确的"),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("mi",null,"n")]),a("annotation",{encoding:"application/x-tex"},"n")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.4306em"}}),a("span",{class:"mord mathnormal"},"n")])])]),e("个组合为正确之外（我们约定这些搭配是正样本），剩下的"),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("msup",null,[a("mi",null,"n"),a("mn",null,"2")]),a("mo",null,"−"),a("mi",null,"n")]),a("annotation",{encoding:"application/x-tex"},"n^2-n")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.8974em","vertical-align":"-0.0833em"}}),a("span",{class:"mord"},[a("span",{class:"mord mathnormal"},"n"),a("span",{class:"msupsub"},[a("span",{class:"vlist-t"},[a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.8141em"}},[a("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[a("span",{class:"pstrut",style:{height:"2.7em"}}),a("span",{class:"sizing reset-size6 size3 mtight"},[a("span",{class:"mord mtight"},"2")])])])])])])]),a("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),a("span",{class:"mbin"},"−"),a("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.4306em"}}),a("span",{class:"mord mathnormal"},"n")])])]),e("都是负样本。训练策略即最大化"),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("msup",null,[a("mi",null,"n"),a("mn",null,"2")])]),a("annotation",{encoding:"application/x-tex"},"n^2")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.8141em"}}),a("span",{class:"mord"},[a("span",{class:"mord mathnormal"},"n"),a("span",{class:"msupsub"},[a("span",{class:"vlist-t"},[a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.8141em"}},[a("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[a("span",{class:"pstrut",style:{height:"2.7em"}}),a("span",{class:"sizing reset-size6 size3 mtight"},[a("span",{class:"mord mtight"},"2")])])])])])])])])])]),e("个匹配中"),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("mi",null,"n")]),a("annotation",{encoding:"application/x-tex"},"n")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.4306em"}}),a("span",{class:"mord mathnormal"},"n")])])]),e("个匹配的余弦相似度，最小化"),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("msup",null,[a("mi",null,"n"),a("mn",null,"2")]),a("mo",null,"−"),a("mi",null,"n")]),a("annotation",{encoding:"application/x-tex"},"n^2-n")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.8974em","vertical-align":"-0.0833em"}}),a("span",{class:"mord"},[a("span",{class:"mord mathnormal"},"n"),a("span",{class:"msupsub"},[a("span",{class:"vlist-t"},[a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.8141em"}},[a("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[a("span",{class:"pstrut",style:{height:"2.7em"}}),a("span",{class:"sizing reset-size6 size3 mtight"},[a("span",{class:"mord mtight"},"2")])])])])])])]),a("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),a("span",{class:"mbin"},"−"),a("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.4306em"}}),a("span",{class:"mord mathnormal"},"n")])])]),e("个负样本的相似度。")],-1),P=a("figure",null,[a("img",{src:x,alt:"alt text",loading:"lazy",decoding:"async"})],-1),$=a("p",null,[e("大致结构是，使用分别的图像处理模型和文本处理模型将图像和文本数据映射到"),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("mi",null,"e"),a("mi",null,"m"),a("mi",null,"b"),a("mi",null,"e"),a("mi",null,"d"),a("mi",null,"d"),a("mi",null,"i"),a("mi",null,"n"),a("mi",null,"g"),a("mi",null,"s"),a("mi",null,"p"),a("mi",null,"a"),a("mi",null,"c"),a("mi",null,"e")]),a("annotation",{encoding:"application/x-tex"},"embedding space")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.8889em","vertical-align":"-0.1944em"}}),a("span",{class:"mord mathnormal"},"e"),a("span",{class:"mord mathnormal"},"mb"),a("span",{class:"mord mathnormal"},"e"),a("span",{class:"mord mathnormal"},"dd"),a("span",{class:"mord mathnormal"},"in"),a("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"g"),a("span",{class:"mord mathnormal"},"s"),a("span",{class:"mord mathnormal"},"p"),a("span",{class:"mord mathnormal"},"a"),a("span",{class:"mord mathnormal"},"ce")])])]),e("中（只通过线性映射），接着通过匹配成不同的对然后训练。")],-1),N=a("p",null,"模型选择方面，image encoder使用了resnet-50, text-encoder使用了transformer。",-1),j={__name:"Learning Transferable Visual Models From Natural Language Supervision",setup(T,{expose:o}){const l=JSON.parse('{"title":"Paper reading--《Learning Transferable Visual Models From Natural Language Supervision》","description":"","frontmatter":{"title":"Paper reading--《Learning Transferable Visual Models From Natural Language Supervision》","date":"2024-11-10","updated":"2024-11-10","excerpt":"经典的CLIP","categories":"Paper-reading","image":"https://raw.githubusercontent.com/xjtu-wjz/void2004/refs/heads/main/pics_for_post/_2024-11-07%20175014.webp","tags":["科研","Generative model"],"top":1},"headers":[],"relativePath":"pages/posts/Learning Transferable Visual Models From Natural Language Supervision.md","path":"/home/runner/work/void2004/void2004/pages/posts/Learning Transferable Visual Models From Natural Language Supervision.md","lastUpdated":1736184181000}'),i=g(),r=l.frontmatter||{};return i.meta.frontmatter=Object.assign(i.meta.frontmatter||{},l.frontmatter||{}),m("pageData",l),m("valaxy:frontmatter",r),globalThis.$frontmatter=r,o({frontmatter:{title:"Paper reading--《Learning Transferable Visual Models From Natural Language Supervision》",date:"2024-11-10",updated:"2024-11-10",excerpt:"经典的CLIP",categories:"Paper-reading",image:"https://raw.githubusercontent.com/xjtu-wjz/void2004/refs/heads/main/pics_for_post/_2024-11-07%20175014.webp",tags:["科研","Generative model"],top:1}}),(t,S)=>{const p=c;return h(),u(p,{frontmatter:d(r)},{"main-content-md":s(()=>[f,w,b,v,_,y,M,k,L,z,P,$,N]),"main-header":s(()=>[n(t.$slots,"main-header")]),"main-header-after":s(()=>[n(t.$slots,"main-header-after")]),"main-nav":s(()=>[n(t.$slots,"main-nav")]),"main-content":s(()=>[n(t.$slots,"main-content")]),"main-content-after":s(()=>[n(t.$slots,"main-content-after")]),"main-nav-before":s(()=>[n(t.$slots,"main-nav-before")]),"main-nav-after":s(()=>[n(t.$slots,"main-nav-after")]),comment:s(()=>[n(t.$slots,"comment")]),footer:s(()=>[n(t.$slots,"footer")]),aside:s(()=>[n(t.$slots,"aside")]),"aside-custom":s(()=>[n(t.$slots,"aside-custom")]),default:s(()=>[n(t.$slots,"default")]),_:3},8,["frontmatter"])}}};export{j as default};
