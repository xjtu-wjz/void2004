import{_ as c}from"./ValaxyMain.vue_vue_type_script_setup_true_lang-D6WepyqT.js";import{b as h,e as d,w as a,f as u,a as g,p as r,r as e,g as s,h as l}from"./app-B5BMfZs9.js";const f=s("h1",{id:"ood简介",tabindex:"-1"},[l("OOD简介 "),s("a",{class:"header-anchor",href:"#ood简介","aria-label":'Permalink to "OOD简介"'},"​")],-1),O=s("p",null,[l("OOD（out of distribution detection）是异常检测（Anomaly Detection）领域的一个重要分支，通俗来讲OOD检测的任务就是"),s("strong",null,"识别出分布与模型训练数据不同的输入数据"),l("。")],-1),v=s("p",null,"最简单的例子： 一个模型接受一堆宠物狗的照片，并试图将他们按照不同品种分成不同的类别。在训练过程中，我们所提供给模型的自然是一堆狗的照片，但是在实际预测过程中，如果输入中混入了其他动物的照片（比如一只猫）那我们当然希望模型能够识别出，这个异常输入（猫）不属于任何一个品种，从而将它划分为分布外数据（即OOD数据）。",-1),b=s("p",null,"由于OOD检测的特殊性，它被广泛应用于增强模型的泛化能力，以及提高模型的鲁棒性，应对可能发生极端情况的场景。例如无人驾驶领域，实验室数据很难模拟实际路况可能发生的极端情景，当无人驾驶的操作系统面临现实中的异常输入时，我们希望模型能够正确识别输入模式并非训练数据中的任何一种模式，从而采取不同的应对方案，而不是继续按照实验训练一样处理，否则可能会造成严重后果。",-1),y=s("p",null,"在正式开始之前，我们重新回顾一下OOD检测中的两个基本概念：",-1),_=s("ul",null,[s("li",null,"OOD：即OOD数据，全称为分布外（out of distribution）数据，是我们希望OOD检测模型能够正确识别并剔除出来的数据。"),s("li",null,"ID：即ID数据，全程分部内数据（in distribution）顾名思义与OOD的概念相对，意味着模型接受数据分布与训练数据集相同。")],-1),x=s("p",null,"下面我们来看几个传统OOD检测基本方向。",-1),D=s("h1",{id:"softmax-based-方法",tabindex:"-1"},[l("softmax-based 方法 "),s("a",{class:"header-anchor",href:"#softmax-based-方法","aria-label":'Permalink to "softmax-based 方法"'},"​")],-1),z=s("p",null,[l("可以先看看softmax的讲解"),s("a",{href:"https://blog.csdn.net/bitcarmanlee/article/details/82320853",target:"_blank",rel:"noreferrer"},"入门级都能看懂的softmax详解-CSDN博客")],-1),w=s("p",null,"OOD检测的softmax-based方法基于softmax概率，大致过程分为以下几步：",-1),P=s("ul",null,[s("li",null,"预训练模型：对网络进行预训练，使其能够在已知的类别上正确进行分类。"),s("li",null,"计算softmax概率分数：网络输出一个分数向量，我们通过softmax方法将其转换为概率分数：")],-1),$=s("p",null,[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"s"),s("mi",null,"o"),s("mi",null,"f"),s("mi",null,"t"),s("mi",null,"m"),s("mi",null,"a"),s("mi",null,"x"),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"x"),s("mi",null,"i")]),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("msup",null,[s("mi",null,"e"),s("msub",null,[s("mi",null,"x"),s("mi",null,"i")])]),s("mi",{mathvariant:"normal"},"/"),s("msub",null,[s("mo",null,"∑"),s("mi",null,"j")]),s("msup",null,[s("mi",null,"e"),s("msub",null,[s("mi",null,"x"),s("mi",null,"j")])])]),s("annotation",{encoding:"application/x-tex"},"softmax(x_{i})=e^{x_{i}}/ \\sum_{j}e^{x_{j}}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"so"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mord mathnormal"},"ma"),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.1858em","vertical-align":"-0.4358em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6644em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3281em"}},[s("span",{style:{top:"-2.357em","margin-left":"0em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.143em"}},[s("span")])])])])])])])])])])])])]),s("span",{class:"mord"},"/"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop"},[s("span",{class:"mop op-symbol small-op",style:{position:"relative",top:"0em"}},"∑"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.162em"}},[s("span",{style:{top:"-2.4003em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"j")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.4358em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6644em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3281em"}},[s("span",{style:{top:"-2.357em","margin-left":"0em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"j")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2819em"}},[s("span")])])])])])])])])])])])])])])])])],-1),k=s("p",null,[l("对于一个ID样本，我们有理由相信模型对于它的分类结果总是比较自信的，所有类别对应的概率分数中的最高项应该明显高于一个阈值 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"γ")]),s("annotation",{encoding:"application/x-tex"},"\\gamma")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.625em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ")])])]),l(" （这个阈值比较empirical，阈值的选取标准也是OOD检测的一个研究方向），如果对于一个样本模型输出的最大概率分数小于这个阈值，我们就可以将他归类为OOD数据，反之为ID数据。")],-1),j=s("h1",{id:"uncertainty-方法",tabindex:"-1"},[l("uncertainty 方法 "),s("a",{class:"header-anchor",href:"#uncertainty-方法","aria-label":'Permalink to "uncertainty 方法"'},"​")],-1),N=s("p",null,"当模型面对OOD数据时，模型输出的不确定性会显著增加，因此也可以将输出的不确定性作为区分ID和OOD样本的依据之一。不确定性检测方法通常与贝叶斯等数学方法挂钩，这里只简单介绍下贝叶斯神经网络（BNN）。BNNs通过在网络的权重上引入概率分布来捕捉不确定性。对于每个输入，网络不仅提供一个预测，还提供预测的不确定性度量。通过多次前向传播（每次使用不同的权重样本）并计算预测的方差，可以估计epistemic uncertainty。",-1),M=s("h1",{id:"pu方法",tabindex:"-1"},[l("PU方法 "),s("a",{class:"header-anchor",href:"#pu方法","aria-label":'Permalink to "PU方法"'},"​")],-1),U=s("p",null,"OOD检测的概念与传统半监督学习（positive and unlabeled learning）有许多相似之处，近年来将PU方法引入OOD检测也是一个新颖的研究方向。 PU方法意味着能提供给样本的数据只有确保为阳性的正样本（positive sample）与没有被打上标签的样本（unlabeled sample），这种情况更接近实际中OOD检测面临的数据分布，因此可以显著提升模型的OOD检测能力。",-1),B=s("p",null,"PU方法通常对已知正样本数据进行特征挖掘，并试图克服没有负样本带来的选择偏差（labeled bias），通常用无标记样本与正样本的特征组合来模拟得到负样本的分布，进而将问题转化为全监督学习。",-1),T={__name:"OOD-intro",setup(I,{expose:o}){const n=JSON.parse('{"title":"Paper reading--《OOD-intro》","description":"","frontmatter":{"title":"Paper reading--《OOD-intro》","date":"2023-09-22","updated":"2024-09-07","categories":"Paper-reading","image":"https://raw.githubusercontent.com/xjtu-wjz/void2004/main/pics/121043535_p0.1aoxfetb9a.webp","tags":["OOD","科研"],"top":1},"headers":[],"relativePath":"pages/posts/OOD-intro.md","path":"/home/runner/work/void2004/void2004/pages/posts/OOD-intro.md","lastUpdated":1736184181000}'),m=g(),i=n.frontmatter||{};return m.meta.frontmatter=Object.assign(m.meta.frontmatter||{},n.frontmatter||{}),r("pageData",n),r("valaxy:frontmatter",i),globalThis.$frontmatter=i,o({frontmatter:{title:"Paper reading--《OOD-intro》",date:"2023-09-22",updated:"2024-09-07",categories:"Paper-reading",image:"https://raw.githubusercontent.com/xjtu-wjz/void2004/main/pics/121043535_p0.1aoxfetb9a.webp",tags:["OOD","科研"],top:1}}),(t,V)=>{const p=c;return h(),d(p,{frontmatter:u(i)},{"main-content-md":a(()=>[f,O,v,b,y,_,x,D,z,w,P,$,k,j,N,M,U,B]),"main-header":a(()=>[e(t.$slots,"main-header")]),"main-header-after":a(()=>[e(t.$slots,"main-header-after")]),"main-nav":a(()=>[e(t.$slots,"main-nav")]),"main-content":a(()=>[e(t.$slots,"main-content")]),"main-content-after":a(()=>[e(t.$slots,"main-content-after")]),"main-nav-before":a(()=>[e(t.$slots,"main-nav-before")]),"main-nav-after":a(()=>[e(t.$slots,"main-nav-after")]),comment:a(()=>[e(t.$slots,"comment")]),footer:a(()=>[e(t.$slots,"footer")]),aside:a(()=>[e(t.$slots,"aside")]),"aside-custom":a(()=>[e(t.$slots,"aside-custom")]),default:a(()=>[e(t.$slots,"default")]),_:3},8,["frontmatter"])}}};export{T as default};
